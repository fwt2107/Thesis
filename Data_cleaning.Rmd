---
title: "Data_cleaning"
author: "Felix Tran"
date: "October 14, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
```

This file documents all the data cleaning and processing for my thesis. Data
from 4 different sources were used. The data are categorized as 1 of 4 kinds -
exposure data, outcome data, covariate data, or mediator data.

# Exposure data - ACS 2012-2016 5-year estimates
County-level income inequality was measured using a Gini coefficient and was
retrieved from the American Community Survey 2012-2016 5-year estimates.

These are the steps I took to clean and process this data:

1. Removed an unneeded ID column

2. Renamed variables for ease of use

3. Created a new variable to separate county name and state
```{r exposure data}
acs_exp_df <- read_csv('./Raw data/County/ACS 2012-2016 Gini.csv', skip = 1) %>% 
  janitor::clean_names() %>% 
  select(-id, 
         county_code = id2, 
         county = geography, 
         gini = estimate_gini_index,
         gini_moe = margin_of_error_gini_index) %>% 
  separate(county, into = c('county', 'state'), sep = ',') %>% 
  mutate(county_code = as.integer(county_code))
```




# Outcome data - CDC WONDER
Suicide rate by county data were retrieved from the CDC WONDER Compressed
Mortality data and exported as a .txt file. Details about the options used when
exporting the data are documented in "CDC wonder query criteria.docx".

These are the steps I took to clean and process the data:

1. Wrote a function to replace suppressed or unreliable rates with NA's

2. The .txt file contained notes about the data at the end of the file. 
These notes were deleted from the dataset, but they can be viewed in 
"CDC wonder notes.docx".

3. I created variables to note if the age-adjusted rate for a particular county
was suppressed or unreliable and therefore unusable, or not.

4. Converted the usable age-adjusted rates into numeric, and changed the name of
the standard error variable for ease of use.
```{r outcome data}
clean_rates <- function(x) {
  unusable <- which(str_detect(x, "Unreliable") | 
                      str_detect(x, "Suppressed"))
  x[unusable] <- NA
  x
}

cdc_df <- readr::read_tsv('./Raw data/County/Compressed Mortality, 1999-2016.txt') %>% 
  janitor::clean_names() %>% 
  drop_na(county) %>% 
  select(-notes) %>% 
  mutate(suppressed = if_else(deaths == "Suppressed", T, F),
         unreliable = 
           if_else(str_detect(age_adjusted_rate, "Unreliable"), T, F),
         usable = !(suppressed | unreliable)) %>% 
  select(county_code, 
         age_adjusted_rate, 
         age_adjusted_se = age_adjusted_rate_standard_error,
         suppressed,
         unreliable,
         usable) %>% 
  mutate(age_adjusted_rate = clean_rates(age_adjusted_rate)) %>% 
  mutate(county_code = as.integer(county_code),
         age_adjusted_rate = as.numeric(age_adjusted_rate),
         age_adjusted_se = as.numeric(age_adjusted_se))

usable_counties <- length(which(cdc_df$usable))
suppressed_counties <- length(which(cdc_df$suppressed))
unreliable_counties <- length(which(cdc_df$unreliable))
```

After this initial process I am left with age-adjusted suicide rates for 
`r usable_counties` counties.




# Covariates
Covariates for this analysis are: race/ethnicity, gender, county 
urban/ruralness, educational attainment, age, absolute income level, and 
poverty.

Studies and vital stats have shown that age-adjusted suicide rates differ based
on these variables and thus should be adjusted for in analyses.

### Urban/rural classification
Urban/rural classification is determined by the NCHS. The NCHS most recently
classified counties in 2013.

These are the steps I took to clean the data:

1. Keep only the county code and urban/rural classification

2. Changed variable names for ease of use
```{r covariate urban/rural}
nchs_df <- readxl::read_excel('./Raw data/County/NCHSURCodes2013.xlsx') %>% 
  janitor::clean_names() %>%
  select(county_code = fips_code,
         urban_rural_code = x2013_code) %>% 
  mutate(county_code = as.integer(county_code))
```


### Mean and median household income
Mean and median household income was collected from the ACS 2012-2016 5 year 
data.

These are the steps I took to clean the data:

1. Deleted the 1st row of the dataset which contains unneeded notes

2. Only keep information for county code, county name, mean income and margin
of error, median income and margin of error, and poverty and margin of error.
```{r covariate absolute income/poverty}
acs_income_df <- read_csv('./Raw data/County/ACS 2012-2016 Economics.csv')
acs_income_df <- acs_income_df[-1, ]
acs_income_df <- acs_income_df %>% 
  janitor::clean_names() %>%
  select(county_code = geo_id2,
         mean_income = hc01_vc85,
         mean_income_moe = hc02_vc85,
         median_income = hc01_vc86,
         median_income_moe = hc02_vc86,
         poverty_prop = hc03_vc171,
         poverty_prop_moe = hc04_vc171) %>% 
  mutate(county_code = as.integer(county_code))
```


### Educational attainment
Educational attainment is operatioanlized as the proportion of the county
population with a college education or greater. This was retrieved from the 
ACS 2012-2016 5 year estimate data.

These are the steps I took to clean the data:

1. Only kept variables for the county code, % of total population with college
education or higher, and the margin of error for the % of total population
with college education or higher

2. Remove an unneeded line of notes from the dataset
```{r covariate education}
edu_df <- read_csv('./Raw data/County/ACS 2012-2016 Education.csv') %>% 
  janitor::clean_names() %>% 
  select(county_code = geo_id2,
         college_prop = hc02_est_vc18,
         college_prop_moe = hc02_moe_vc18) %>% 
  mutate(county_code = as.integer(county_code))
edu_df <- edu_df[-1, ]
```


### Race/ethnicity and gender
Race/ethnicity, gender, and age were retrieved from the ACS 2012-2016 5 year 
estimate data. Studies and vital stats have indicated that non-Hispanic whites 
have higher age-adjusted rates of suicide compared to other racial/ethnic
groups, males have greater age-adjusted rates of suicide compared to females,
and the elderly (65 years and older) have greater rates of suicide compared to
other age groups.

These are the steps I took to clean the data:

1. Only kept variables for county code, % of total population that identified
as white, % of total population that is male, % of total population that is 65
years and older, and the margins of error for these estimates

2. Removed a row of unneeded notes from the data
```{r covariate gender/race/age}
gender_race_df <- read_csv('./Raw data/County/ACS 2012-2016 Demographics.csv') %>% 
  janitor::clean_names() %>% 
  select(county_code = geo_id2,
         male_prop = hc03_vc04,
         male_prop_moe = hc04_vc04,
         white_prop = hc03_vc94,
         white_prop_moe = hc04_vc94,
         geriatric_prop = hc03_vc29,
         geriatric_prop_moe = hc04_vc29) %>% 
  mutate(county_code = as.integer(county_code))
gender_race_df <- gender_race_df[-1, ]
```




# Mediator - Social capital
Social capital was measured by the method described in Rupasingha et al (2006).
```{r mediator data}
socialcap_df <- readxl::read_excel('./Raw data/County/Social capital 2014.xlsx') %>% 
  janitor::clean_names() %>% 
  mutate(county_code = as.integer(fips)) %>% 
  select(-fips)
```




# Combining datasets
This section combines all the datasets into 1 cohesive dataset containing all
exposure, outcome, covariate, and mediator information.

The Federal Information Processing Standard Publication 6-4 is a 5-digit code 
used to identify counties/county equivalents in the US. Datasets will be 
merged by this county code.
```{r merge datasets}
final_df <- left_join(acs_exp_df, cdc_df, by = "county_code") %>% 
  left_join(., acs_income_df, by = "county_code") %>% 
  left_join(., nchs_df, by = "county_code") %>% 
  left_join(., edu_df, by = "county_code") %>% 
  left_join(., socialcap_df, by = "county_code") %>% 
  left_join(., gender_race_df, by = "county_code")
```

I then saved the final dataset as a csv file for future analyses.
```{r save final dataset}
write_csv(final_df, path = "./Cleaned data/County/final_df.csv")
```


